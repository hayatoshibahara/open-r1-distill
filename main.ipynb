{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db3b17e",
   "metadata": {},
   "source": [
    "# Open-R1-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c646831",
   "metadata": {},
   "source": [
    "- [huggingface/open-r1][2]\n",
    "- [open-r1/Mixture-of-Thoughts][1]\n",
    "\n",
    "[1]: https://huggingface.co/datasets/open-r1/Mixture-of-Thoughts\n",
    "[2]: https://github.com/huggingface/open-r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866f5d6",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒæ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25414081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if os.path.exists(\"debug.log\"):\n",
    "    os.remove(\"debug.log\")\n",
    "\n",
    "def custom_format(record):\n",
    "    match record.levelno:\n",
    "        case logging.DEBUG:\n",
    "            level = \"ðŸŸ¦\"\n",
    "        case logging.INFO:\n",
    "            level = \"ðŸŸ©\"\n",
    "        case logging.WARNING:\n",
    "            level = \"ðŸŸ¨\"\n",
    "        case logging.ERROR:\n",
    "            level = \"ðŸŸ¥\"\n",
    "        case logging.CRITICAL:\n",
    "            level = \"ðŸ›‘\"\n",
    "    return f\"{level} {record.getMessage()}\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "for handler in logger.handlers:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "formatter = logging.Formatter()\n",
    "formatter.format = custom_format\n",
    "\n",
    "file_handler = logging.FileHandler(\"debug.log\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "NVIDIA_SMI = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True).stdout\n",
    "logging.info(NVIDIA_SMI)\n",
    "logging.info(f\"Python {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce29f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"12345\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40811ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    if not os.path.exists(\"/content/open-r1\"):\n",
    "        %git clone https://github.com/huggingface/open-r1.git\n",
    "    %cd /content/open-r1\n",
    "    %pip install -e \".[dev]\" --no-deps\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    # !apt update && apt install git-lfs -y\n",
    "    if not os.path.exists(\"/workspaces/open-r1-distill/open-r1\"):\n",
    "        %git clone https://github.com/huggingface/open-r1.git\n",
    "    %cd /workspaces/open-r1-distill/open-r1\n",
    "    %pip install -e \".[dev]\" --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca732ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) PyTorchã¨Transformersã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "%pip install torch==2.6.0 transformers==4.52.3\n",
    "\n",
    "# 2) vLLMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "%pip install vllm==0.8.5.post1\n",
    "\n",
    "# 3) Flash Attentionã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "# 2.8.3ã¯undefined symbolã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ãŸã‚2.7.3ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "# https://github.com/Dao-AILab/flash-attention/issues/1832\n",
    "%pip install \"https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu12torch2.6cxx11abiFALSE-cp312-cp312-linux_x86_64.whl\" --no-build-isolation\n",
    "\n",
    "# 4) ãã®ä»–ã®å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "%pip install \\\n",
    "    accelerate==1.4.0 \\\n",
    "    beautifulsoup4 \\\n",
    "    \"async-lru\" \\\n",
    "    bitsandbytes \\\n",
    "    \"distilabel[vllm]\" \\\n",
    "    deepspeed==0.16.8 \\\n",
    "    hf_transfer \\\n",
    "    langdetect \\\n",
    "    latex2sympy2_extended \\\n",
    "    liger-kernel \\\n",
    "    \"trl[vllm]==0.18.0\" \\\n",
    "    math-verify==0.5.2 \\\n",
    "    wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97498f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from distilabel.models import vLLM\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps.tasks import TextGeneration\n",
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c803c6",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef900c",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c234e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72400ä»¶ã®æ•°å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
    "# https://huggingface.co/datasets/AI-MO/NuminaMath-TIR\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ã—ã ã‘å–å¾—\n",
    "dataset = load_dataset(\n",
    "    \"AI-MO/NuminaMath-TIR\",\n",
    "    split=\"train\",\n",
    ").select(range(10))\n",
    "\n",
    "logger.info(f\"{len(dataset)=} {dataset[0].keys()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99118f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problemã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º\n",
    "logger.info(f\"Problem:\\n{dataset[0]['problem']}\")\n",
    "\n",
    "# (3/5x - 2/y)^8ã®å±•é–‹å¼ã«ãŠã‘ã‚‹x^2y^6ã®ä¿‚æ•°ã‚’åˆ†æ•°ã§æ±‚ã‚ã‚ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutionã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º\n",
    "logger.info(f\"Solution:\\n{dataset[0]['solution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84007cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messagesã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º\n",
    "logger.info(f'messages\\n{dataset[0][\"messages\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd70d2b",
   "metadata": {},
   "source": [
    "### ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§æŽ¨è«–ã—ã€æœ€çµ‚å›žç­”ã‚’\\boxed{}ã§å›²ã£ã¦ãã ã•ã„\n",
    "prompt_template = \"\"\"\\\n",
    "You will be given a problem. Please reason step by step, and put your final answer within \\boxed{}:\n",
    "{{ instruction }}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è’¸ç•™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ\n",
    "\n",
    "# è’¸ç•™å…ƒã®ãƒ¢ãƒ‡ãƒ«\n",
    "# https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "with Pipeline(\n",
    "    name=\"distill-qwen-1.5b-r1\",\n",
    "    description=\"A pipeline to generate data from a distilled r1 model\",\n",
    ") as pipeline:\n",
    "\n",
    "    # distilabelã®vLLMã‚’åˆæœŸåŒ–\n",
    "    # https://distilabel.argilla.io/dev/components-gallery/llms/vllm/?h=vllm\n",
    "    llm = vLLM(\n",
    "        model=model_id,\n",
    "        tokenizer=model_id,\n",
    "        extra_kwargs={\n",
    "            \"tensor_parallel_size\": 1,\n",
    "            \"max_model_len\": 1024, # 8192\n",
    "        },\n",
    "        generation_kwargs={\n",
    "            \"temperature\": 0.6,\n",
    "            \"max_new_tokens\": 1024, # 8192\n",
    "        },\n",
    "    )\n",
    "\n",
    "    prompt_column = \"problem\"\n",
    "\n",
    "    text_generation = TextGeneration(\n",
    "        llm=llm, \n",
    "        template=prompt_template,\n",
    "        num_generations=4, # 1ã¤ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦4ã¤ç”Ÿæˆ\n",
    "        input_mappings={\"instruction\": prompt_column} if prompt_column is not None else {}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214396f9",
   "metadata": {},
   "source": [
    "### ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distiset = pipeline.run(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec761766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 * 4 = 40ä»¶ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹\n",
    "logger.info(f\"{distiset=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è’¸ç•™å…ƒã®ãƒ¢ãƒ‡ãƒ«å\n",
    "print(distiset[\"default\"][\"train\"][0][\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425af5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "print(distiset[\"default\"][\"train\"][0][\"distilabel_metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆçµæžœ\n",
    "print(distiset[\"default\"][\"train\"][0][\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d4779",
   "metadata": {},
   "source": [
    "## SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98223586",
   "metadata": {},
   "source": [
    "```sh\n",
    "python src/open_r1/sft.py \\\n",
    "    --config recipes/OpenR1-Distill-7B/sft/config_distill.yaml \\\n",
    "    --model_name_or_path Qwen/Qwen3-0.6B-Base \\\n",
    "    --hub_model_id OpenR1-Distill-0.6B \\\n",
    "    --output_dir data/OpenR1-Distill-0.6B \\\n",
    "    --push_to_hub False \\\n",
    "    --report_to none\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "from datasets import load_dataset\n",
    "from functools import partial, update_wrapper\n",
    "from latex2sympy2_extended import NormalizationConfig\n",
    "from math_verify import LatexExtractionConfig, parse, verify\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer\n",
    "from transformers import set_seed\n",
    "from transformers import TrainerCallback\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.training_args import TrainingArguments\n",
    "from trl import GRPOTrainer, ModelConfig, TrlParser, get_peft_config\n",
    "from trl import ModelConfig, get_kbit_device_map, get_quantization_config\n",
    "from trl import ModelConfig, SFTTrainer, TrlParser, get_peft_config, setup_chat_format\n",
    "from typing import Any, Callable, Dict, Literal, List, Optional\n",
    "import asyncio\n",
    "import datasets\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import transformers\n",
    "import trl\n",
    "\n",
    "logger.info(f\"transformers: {transformers.__version__}\") # 4.52.3\n",
    "logger.info(f\"torch: {torch.__version__}\") # 2.6.0+cu124\n",
    "logger.info(f\"trl: {trl.__version__}\") # 0.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afab7e",
   "metadata": {},
   "source": [
    "### è¨­å®šã‚¯ãƒ©ã‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9dbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScriptArguments(trl.ScriptArguments):\n",
    "    \"\"\"\n",
    "    Extended version of ScriptArguments with support for dataset mixtures.\n",
    "\n",
    "    Args:\n",
    "        dataset_mixture (`dict[str, Any]` or `None`, *optional*, defaults to `None`):\n",
    "            Configuration for creating dataset mixtures with advanced options.\n",
    "            Format:\n",
    "              dataset_mixture:\n",
    "                datasets:\n",
    "                  - id: dataset_id1\n",
    "                    config: config_name\n",
    "                    columns:\n",
    "                      - col1\n",
    "                      - col2\n",
    "                    weight: 0.5\n",
    "                  - id: dataset_id2\n",
    "                    config: config_name\n",
    "                    columns:\n",
    "                      - col1\n",
    "                      - col2\n",
    "                    weight: 0.5\n",
    "                seed: 42\n",
    "                test_split_size: 0.1\n",
    "    \"\"\"\n",
    "\n",
    "    # Override the dataset_name to make it optional\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Dataset name. Can be omitted if using dataset_mixture.\"}\n",
    "    )\n",
    "    dataset_mixture: Optional[dict[str, Any]] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Configuration for creating dataset mixtures with advanced options like shuffling.\"},\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.dataset_name is None and self.dataset_mixture is None:\n",
    "            raise ValueError(\"Either `dataset_name` or `dataset_mixture` must be provided\")\n",
    "\n",
    "        if self.dataset_mixture is not None:\n",
    "            if not isinstance(self.dataset_mixture, dict) or \"datasets\" not in self.dataset_mixture:\n",
    "                raise ValueError(\n",
    "                    \"dataset_mixture must be a dictionary with a 'datasets' key. \"\n",
    "                    \"Expected format: {'datasets': [...], 'seed': int}\"\n",
    "                )\n",
    "\n",
    "            datasets_list = []\n",
    "            datasets_data = self.dataset_mixture.get(\"datasets\", [])\n",
    "\n",
    "            if isinstance(datasets_data, list):\n",
    "                for dataset_config in datasets_data:\n",
    "                    datasets_list.append(\n",
    "                        DatasetConfig(\n",
    "                            id=dataset_config.get(\"id\"),\n",
    "                            config=dataset_config.get(\"config\"),\n",
    "                            split=dataset_config.get(\"split\", \"train\"),\n",
    "                            columns=dataset_config.get(\"columns\"),\n",
    "                            weight=dataset_config.get(\"weight\", 1.0),\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\"'datasets' must be a list of dataset configurations\")\n",
    "\n",
    "            self.dataset_mixture = DatasetMixtureConfig(\n",
    "                datasets=datasets_list,\n",
    "                seed=self.dataset_mixture.get(\"seed\", 0),\n",
    "                test_split_size=self.dataset_mixture.get(\"test_split_size\", None),\n",
    "            )\n",
    "\n",
    "            # Check that column names are consistent across all dataset configs\n",
    "            columns_sets = [set(dataset.columns) for dataset in datasets_list if dataset.columns is not None]\n",
    "            if columns_sets:\n",
    "                first_columns = columns_sets[0]\n",
    "                if not all(columns == first_columns for columns in columns_sets):\n",
    "                    raise ValueError(\n",
    "                        \"Column names must be consistent across all dataset configurations in a mixture. \"\n",
    "                        f\"Found different column sets: {[list(cols) for cols in columns_sets]}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SFTConfig(trl.SFTConfig):\n",
    "    \"\"\"\n",
    "    args for callbacks, benchmarks etc\n",
    "    \"\"\"\n",
    "\n",
    "    benchmarks: list[str] = field(\n",
    "        default_factory=lambda: [],\n",
    "        metadata={\"help\": \"The benchmarks to run after training.\"},\n",
    "    )\n",
    "    callbacks: list[str] = field(\n",
    "        default_factory=lambda: [],\n",
    "        metadata={\"help\": \"The callbacks to run during training.\"},\n",
    "    )\n",
    "    chat_template: Optional[str] = field(default=None, metadata={\"help\": \"The chat template to use.\"})\n",
    "    system_prompt: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The optional system prompt to use for benchmarking.\"},\n",
    "    )\n",
    "    hub_model_revision: Optional[str] = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The Hub model branch to push the model to.\"},\n",
    "    )\n",
    "    overwrite_hub_revision: bool = field(default=False, metadata={\"help\": \"Whether to overwrite the Hub revision.\"})\n",
    "    push_to_hub_revision: bool = field(default=False, metadata={\"help\": \"Whether to push to a Hub revision/branch.\"})\n",
    "    wandb_entity: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": (\"The entity to store runs under.\")},\n",
    "    )\n",
    "    wandb_project: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": (\"The project to store runs under.\")},\n",
    "    )\n",
    "    wandb_run_group: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": (\"The group to store runs under.\")},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89222744",
   "metadata": {},
   "source": [
    "### ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(args: ScriptArguments) -> DatasetDict:\n",
    "    \"\"\"Load a dataset or a mixture of datasets based on the configuration.\n",
    "\n",
    "    Args:\n",
    "        args (ScriptArguments): Script arguments containing dataset configuration.\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict: The loaded datasets.\n",
    "    \"\"\"\n",
    "    if args.dataset_name and not args.dataset_mixture:\n",
    "        logger.info(f\"Loading dataset: {args.dataset_name}\")\n",
    "        return datasets.load_dataset(args.dataset_name, args.dataset_config)\n",
    "    elif args.dataset_mixture:\n",
    "        logger.info(f\"Creating dataset mixture with {len(args.dataset_mixture.datasets)} datasets\")\n",
    "        seed = args.dataset_mixture.seed\n",
    "        datasets_list = []\n",
    "\n",
    "        for dataset_config in args.dataset_mixture.datasets:\n",
    "            logger.info(f\"Loading dataset for mixture: {dataset_config.id} (config: {dataset_config.config})\")\n",
    "            ds = datasets.load_dataset(\n",
    "                dataset_config.id,\n",
    "                dataset_config.config,\n",
    "                split=dataset_config.split,\n",
    "            )\n",
    "            if dataset_config.columns is not None:\n",
    "                ds = ds.select_columns(dataset_config.columns)\n",
    "            if dataset_config.weight is not None:\n",
    "                ds = ds.shuffle(seed=seed).select(range(int(len(ds) * dataset_config.weight)))\n",
    "                logger.info(\n",
    "                    f\"Subsampled dataset '{dataset_config.id}' (config: {dataset_config.config}) with weight={dataset_config.weight} to {len(ds)} examples\"\n",
    "                )\n",
    "\n",
    "            datasets_list.append(ds)\n",
    "\n",
    "        if datasets_list:\n",
    "            combined_dataset = concatenate_datasets(datasets_list)\n",
    "            combined_dataset = combined_dataset.shuffle(seed=seed)\n",
    "            logger.info(f\"Created dataset mixture with {len(combined_dataset)} examples\")\n",
    "\n",
    "            if args.dataset_mixture.test_split_size is not None:\n",
    "                combined_dataset = combined_dataset.train_test_split(\n",
    "                    test_size=args.dataset_mixture.test_split_size, seed=seed\n",
    "                )\n",
    "                logger.info(\n",
    "                    f\"Split dataset into train and test sets with test size: {args.dataset_mixture.test_split_size}\"\n",
    "                )\n",
    "                return combined_dataset\n",
    "            else:\n",
    "                return DatasetDict({\"train\": combined_dataset})\n",
    "        else:\n",
    "            raise ValueError(\"No datasets were loaded from the mixture configuration\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either `dataset_name` or `dataset_mixture` must be provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(model_args: ModelConfig, training_args: Any) -> PreTrainedTokenizer:\n",
    "    \"\"\"Get the tokenizer for the model.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        revision=model_args.model_revision,\n",
    "        trust_remote_code=model_args.trust_remote_code,\n",
    "    )\n",
    "\n",
    "    if training_args.chat_template is not None:\n",
    "        tokenizer.chat_template = training_args.chat_template\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03433ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_args: ModelConfig, training_args: SFTConfig) -> AutoModelForCausalLM:\n",
    "    \"\"\"Get the model\"\"\"\n",
    "    torch_dtype = (\n",
    "        model_args.torch_dtype if model_args.torch_dtype in [\"auto\", None] else getattr(torch, model_args.torch_dtype)\n",
    "    )\n",
    "    quantization_config = get_quantization_config(model_args)\n",
    "    model_kwargs = dict(\n",
    "        revision=model_args.model_revision,\n",
    "        trust_remote_code=model_args.trust_remote_code,\n",
    "        attn_implementation=model_args.attn_implementation,\n",
    "        torch_dtype=torch_dtype,\n",
    "        use_cache=False if training_args.gradient_checkpointing else True,\n",
    "        device_map=get_kbit_device_map() if quantization_config is not None else None,\n",
    "        quantization_config=quantization_config,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23024e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(train_config, model_config) -> List[TrainerCallback]:\n",
    "    callbacks = []\n",
    "    # for callback_name in train_config.callbacks:\n",
    "    #     if callback_name not in CALLBACKS:\n",
    "    #         raise ValueError(f\"Callback {callback_name} not found in CALLBACKS.\")\n",
    "    #     callbacks.append(CALLBACKS[callback_name](model_config))\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wandb_training(training_args):\n",
    "    \"\"\"\n",
    "    Helper function for setting up Weights & Biases logging tools.\n",
    "    \"\"\"\n",
    "    if training_args.wandb_entity is not None:\n",
    "        os.environ[\"WANDB_ENTITY\"] = training_args.wandb_entity\n",
    "    if training_args.wandb_project is not None:\n",
    "        os.environ[\"WANDB_PROJECT\"] = training_args.wandb_project\n",
    "    if training_args.wandb_run_group is not None:\n",
    "        os.environ[\"WANDB_RUN_GROUP\"] = training_args.wandb_run_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb7f09",
   "metadata": {},
   "source": [
    "### è¨“ç·´è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelConfig(\n",
    "    # model_name_or_path=\"open-r1/Qwen2.5-Math-7B-RoPE-300k\",\n",
    "    model_name_or_path=\"Qwen/Qwen3-0.6B-Base\",\n",
    "    model_revision=\"main\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    bf16=True,\n",
    "    do_eval=False,\n",
    "    eval_strategy=\"no\",\n",
    "    # gradient_accumulation_steps=8,\n",
    "    gradient_accumulation_steps=32,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    hub_model_id=\"OpenR1-Distill-0.6B\", # \"OpenR1-Distill-7B\"\n",
    "    hub_strategy=\"every_save\",\n",
    "    learning_rate=4.0e-5,\n",
    "    log_level=\"info\",\n",
    "    logging_steps=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine_with_min_lr\",\n",
    "    lr_scheduler_kwargs={\"min_lr_rate\": 0.1},\n",
    "    packing=False,\n",
    "    max_grad_norm=0.2,\n",
    "    max_length=32768,\n",
    "    max_steps=1, # -1\n",
    "    num_train_epochs=1, # 5\n",
    "    output_dir=\"data/OpenR1-Distill-0.6B\", # \"data/OpenR1-Distill-7B\"\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_eval_batch_size=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    push_to_hub=False, # True\n",
    "    report_to=[], # [\"wandb\"]\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    use_liger_kernel=True,\n",
    "    warmup_ratio=0.03,\n",
    "    dataset_num_proc=12,\n",
    "    eos_token=\"<|im_end|>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1361e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/open-r1/Mixture-of-Thoughts\n",
    "\n",
    "script_args = ScriptArguments(\n",
    "    dataset_name=\"open-r1/Mixture-of-Thoughts\",\n",
    "    dataset_config=\"math\", # \"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b0a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for last checkpoint\n",
    "last_checkpoint = None\n",
    "\n",
    "if os.path.isdir(training_args.output_dir):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "\n",
    "if last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "    logger.info(f\"Checkpoint detected, resuming training at {last_checkpoint=}.\")\n",
    "\n",
    "if \"wandb\" in training_args.report_to:\n",
    "    init_wandb_training(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65a680",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88323001",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(script_args)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].select(range(1000))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028ecc6",
   "metadata": {},
   "source": [
    "### ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb95957",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(model_args, training_args)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.chat_template is None:\n",
    "    logger.info(\"No chat template provided, defaulting to ChatML.\")\n",
    "    model, tokenizer = setup_chat_format(model, tokenizer, format=\"chatml\")\n",
    "\n",
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d578534",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_args, training_args)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286604dd",
   "metadata": {},
   "source": [
    "### SFTTrainerã®ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[script_args.dataset_train_split],\n",
    "    eval_dataset=(dataset[script_args.dataset_test_split] if training_args.eval_strategy != \"no\" else None),\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=get_peft_config(model_args),\n",
    "    callbacks=get_callbacks(training_args, model_args),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d7f8f",
   "metadata": {},
   "source": [
    "### è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48698aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = None\n",
    "\n",
    "if training_args.resume_from_checkpoint is not None:\n",
    "    checkpoint = training_args.resume_from_checkpoint\n",
    "elif last_checkpoint is not None:\n",
    "    checkpoint = last_checkpoint\n",
    "\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75af911",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train(resume_from_checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43e34a",
   "metadata": {},
   "source": [
    "### ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train_result.metrics\n",
    "metrics[\"train_samples\"] = len(dataset[script_args.dataset_train_split])\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560407d0",
   "metadata": {},
   "source": [
    "### ãƒ¡ãƒ¢ãƒªé–‹æ”¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in [\"dataset\", \"tokenizer\", \"model\", \"trainer\", \"trainer_result\", \"mertics\"]:\n",
    "    try:\n",
    "        del globals()[target]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996b621",
   "metadata": {},
   "source": [
    "## GRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce55fb",
   "metadata": {},
   "source": [
    "```sh\n",
    "!RANK=0 WORLD_SIZE=1 LOCAL_RANK=0 MASTER_ADDR=localhost MASTER_PORT=12345 python src/open_r1/grpo.py \\\n",
    "    --config recipes/DeepSeek-R1-Distill-Qwen-1.5B/grpo/config_demo.yaml \\\n",
    "    --model_name_or_path Qwen/Qwen3-0.6B-Base \\\n",
    "    --hub_model_id OpenR1-Distill-0.6B \\\n",
    "    --output_dir data/OpenR1-Distill-0.6B \\\n",
    "    --push_to_hub False \\\n",
    "    --report_to none \\\n",
    "    --vllm_mode colocate \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --num_generations 4 \\\n",
    "    --gradient_accumulation_steps 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "from datasets import load_dataset\n",
    "from functools import partial, update_wrapper\n",
    "from latex2sympy2_extended import NormalizationConfig\n",
    "from math_verify import LatexExtractionConfig, parse, verify\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer\n",
    "from transformers import set_seed\n",
    "from transformers import TrainerCallback\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.training_args import TrainingArguments\n",
    "from trl import GRPOTrainer, ModelConfig, TrlParser, get_peft_config\n",
    "from trl import ModelConfig, get_kbit_device_map, get_quantization_config\n",
    "from trl import ModelConfig, SFTTrainer, TrlParser, get_peft_config, setup_chat_format\n",
    "from typing import Any, Callable, Dict, Literal, List, Optional\n",
    "import asyncio\n",
    "import datasets\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import transformers\n",
    "import trl\n",
    "\n",
    "logger.info(f\"transformers: {transformers.__version__}\") # 4.52.3\n",
    "logger.info(f\"torch: {torch.__version__}\") # 2.6.0+cu124\n",
    "logger.info(f\"trl: {trl.__version__}\") # 0.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd28d2e",
   "metadata": {},
   "source": [
    "### è¨­å®šã‚¯ãƒ©ã‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a19b3ce",
   "metadata": {},
   "source": [
    "#### GRPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d502a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GRPOConfig(trl.GRPOConfig):\n",
    "    \"\"\"\n",
    "    args for callbacks, benchmarks etc\n",
    "    \"\"\"\n",
    "\n",
    "    benchmarks: list[str] = field(\n",
    "        default_factory=lambda: [],\n",
    "        metadata={\"help\": \"The benchmarks to run after training.\"},\n",
    "    )\n",
    "    callbacks: list[str] = field(\n",
    "        default_factory=lambda: [],\n",
    "        metadata={\"help\": \"The callbacks to run during training.\"},\n",
    "    )\n",
    "    chat_template: Optional[str] = field(default=None, metadata={\"help\": \"The chat template to use.\"})\n",
    "    hub_model_revision: Optional[str] = field(\n",
    "        default=\"main\", metadata={\"help\": \"The Hub model branch to push the model to.\"}\n",
    "    )\n",
    "    num_completions_to_print: int = field(default=0, metadata={\"help\": \"Number of completions to print.\"})\n",
    "    overwrite_hub_revision: bool = field(default=False, metadata={\"help\": \"Whether to overwrite the Hub revision.\"})\n",
    "    push_to_hub_revision: bool = field(default=False, metadata={\"help\": \"Whether to push to a Hub revision/branch.\"})\n",
    "    system_prompt: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The optional system prompt to use.\"},\n",
    "    )\n",
    "    wandb_log_unique_prompts: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": (\"Whether to log the unique prompts to wandb. This will create a new run for each unique prompt.\")\n",
    "        },\n",
    "    )\n",
    "    wandb_entity: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": (\"The entity to store runs under.\")},\n",
    "    )\n",
    "    wandb_project: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": (\"The project to store runs under.\")},\n",
    "    )\n",
    "    wandb_run_group: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": (\"The group to store runs under.\")},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e555ae4",
   "metadata": {},
   "source": [
    "#### GRPOScriptArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09213c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class GRPOScriptArguments(ScriptArguments):\n",
    "    \"\"\"\n",
    "    Script arguments for the GRPO training script.\n",
    "\n",
    "    Args:\n",
    "        reward_funcs (`list[str]`):\n",
    "            List of reward functions. Possible values: 'accuracy', 'format', 'reasoning_steps', 'cosine', 'repetition_penalty', 'length', 'tag_count', 'code', 'ioi_code', 'code_format', 'soft_overlong_punishment'.\n",
    "        cosine_min_value_wrong (`float`):\n",
    "            Minimum reward for cosine scaling for wrong answers.\n",
    "        cosine_max_value_wrong (`float`):\n",
    "            Maximum reward for cosine scaling for wrong answers.\n",
    "        cosine_min_value_correct (`float`):\n",
    "            Minimum reward for cosine scaling for correct answers.\n",
    "        cosine_max_value_correct (`float`):\n",
    "            Maximum reward for cosine scaling for correct answers.\n",
    "        cosine_max_len (`int`):\n",
    "            Maximum length for cosine scaling.\n",
    "        code_language (`str`):\n",
    "            Language for code format reward.\n",
    "        max_completion_len (`int`):\n",
    "            Maximum number of tokens in completion.\n",
    "        soft_punish_cache (`int`):\n",
    "            Minimum number of tokens in completion.\n",
    "    \"\"\"\n",
    "\n",
    "    reward_funcs: list[str] = field(\n",
    "        default_factory=lambda: [\"accuracy\", \"format\", \"tag_count\"],\n",
    "        metadata={\n",
    "            \"help\": \"List of reward functions. Possible values: 'accuracy', 'format', 'reasoning_steps', 'cosine', 'repetition_penalty', 'length', tag_count', 'code', 'code_format'\"\n",
    "        },\n",
    "    )\n",
    "    cosine_min_value_wrong: float = field(\n",
    "        default=0.0,\n",
    "        metadata={\"help\": \"Minimum reward for wrong answers\"},\n",
    "    )\n",
    "    cosine_max_value_wrong: float = field(\n",
    "        default=-0.5,\n",
    "        metadata={\"help\": \"Maximum reward for wrong answers\"},\n",
    "    )\n",
    "    cosine_min_value_correct: float = field(\n",
    "        default=0.5,\n",
    "        metadata={\"help\": \"Minimum reward for correct answers\"},\n",
    "    )\n",
    "    cosine_max_value_correct: float = field(\n",
    "        default=1.0,\n",
    "        metadata={\"help\": \"Maximum reward for correct answers\"},\n",
    "    )\n",
    "    cosine_max_len: int = field(\n",
    "        default=1000,\n",
    "        metadata={\"help\": \"Maximum length for scaling\"},\n",
    "    )\n",
    "    repetition_n_grams: int = field(\n",
    "        default=3,\n",
    "        metadata={\"help\": \"Number of n-grams for repetition penalty reward\"},\n",
    "    )\n",
    "    repetition_max_penalty: float = field(\n",
    "        default=-1.0,\n",
    "        metadata={\"help\": \"Maximum (negative) penalty for for repetition penalty reward\"},\n",
    "    )\n",
    "    code_language: str = field(\n",
    "        default=\"python\",\n",
    "        # '(?:python|cpp)'\n",
    "        metadata={\n",
    "            \"help\": \"Language for code format reward. Based on E2B supported languages https://e2b.dev/docs/code-interpreting/supported-languages\",\n",
    "            \"choices\": [\"python\", \"javascript\", \"r\", \"java\", \"bash\", \"cpp\"],\n",
    "        },\n",
    "    )\n",
    "    code_eval_test_batch_size: int = field(\n",
    "        default=1,\n",
    "        metadata={\n",
    "            \"help\": \"for each generation, evaluate these many test cases in parallel, then check if any of them failed (0 score): if so stop evaluating; otherwise continue with the next batch of test cases. Useful to avoid overloading the eval server + save time on wrong solutions\"\n",
    "        },\n",
    "    )\n",
    "    code_eval_scoring_mode: Literal[\"pass_fail\", \"partial\", \"weighted_sum\"] = field(\n",
    "        default=\"weighted_sum\",\n",
    "        metadata={\"help\": \"use fraction of passed test cases as reward. If false, use 0/1 scoring.\"},\n",
    "    )\n",
    "    parallel_code_exec_per_proc: int = field(\n",
    "        default=2,\n",
    "        metadata={\n",
    "            \"help\": \"Number of parallel E2B code executions per process. Default of 2 is suitable for the Free Hobby tier of E2B with 8 GPUs used for training.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    dataset_prompt_column: str = field(\n",
    "        default=\"prompt\",\n",
    "        metadata={\"help\": \"Column to use as prompts for training.\"},\n",
    "    )\n",
    "\n",
    "    e2b_router_url: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"URL for the E2B router. See scripts/e2b_router.py\"},\n",
    "    )\n",
    "\n",
    "    morph_router_url: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"URL for the MorphCloud router. See scripts/morph_router.py\"},\n",
    "    )\n",
    "\n",
    "    code_provider: Optional[str] = field(\n",
    "        default=\"e2b\",\n",
    "        metadata={\n",
    "            \"help\": \"Provider for code execution. Options: 'e2b', 'local', 'morph'.\",\n",
    "            \"choices\": [\"e2b\", \"local\", \"morph\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    ioi_provider: Optional[str] = field(\n",
    "        default=\"piston\",\n",
    "        metadata={\n",
    "            \"help\": \"Provider for IOI code execution. Options: 'piston', 'morph'.\",\n",
    "            \"choices\": [\"piston\", \"morph\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    max_completion_len: int = field(\n",
    "        default=16384,\n",
    "        metadata={\"help\": \"Maximum number of characters in completion.\"},\n",
    "    )\n",
    "    soft_punish_cache: int = field(\n",
    "        default=4096,\n",
    "        metadata={\"help\": \"Minimum number of characters in completion.\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657baa1",
   "metadata": {},
   "source": [
    "### å ±é…¬é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reward(completions: list[list[dict[str, str]]], solution: list[str], **kwargs) -> list[Optional[float]]:\n",
    "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "    for content, sol in zip(contents, solution):\n",
    "        gold_parsed = parse(\n",
    "            sol,\n",
    "            extraction_mode=\"first_match\",\n",
    "        )\n",
    "        if len(gold_parsed) != 0:\n",
    "            # We require the answer to be provided in correct latex (no malformed operators)\n",
    "            answer_parsed = parse(\n",
    "                content,\n",
    "                extraction_config=[\n",
    "                    LatexExtractionConfig(\n",
    "                        normalization_config=NormalizationConfig(\n",
    "                            nits=False,\n",
    "                            malformed_operators=False,\n",
    "                            basic_latex=True,\n",
    "                            equations=True,\n",
    "                            boxed=\"all\",\n",
    "                            units=True,\n",
    "                        ),\n",
    "                        # Ensures that boxed is tried first\n",
    "                        boxed_match_priority=0,\n",
    "                        try_extract_without_anchor=False,\n",
    "                    )\n",
    "                ],\n",
    "                extraction_mode=\"first_match\",\n",
    "            )\n",
    "            # Compute binary rewards if verifiable, `None` otherwise to skip this example\n",
    "            try:\n",
    "                reward = float(verify(gold_parsed, answer_parsed))\n",
    "            except Exception as e:\n",
    "                print(f\"verify failed: {e}, answer: {answer_parsed}, gold: {gold_parsed}\")\n",
    "                reward = None\n",
    "        else:\n",
    "            # If the gold solution is not parseable, we assign `None` to skip this example\n",
    "            reward = None\n",
    "            print(\"Failed to parse gold solution: \", sol)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91711692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the reasoning process is enclosed within <think> and </think> tags, while the final answer is enclosed within <answer> and </answer> tags.\"\"\"\n",
    "    pattern = r\"^<think>\\n.*?\\n</think>\\n<answer>\\n.*?\\n</answer>$\"\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, content, re.DOTALL | re.MULTILINE) for content in completion_contents]\n",
    "    return [1.0 if match else 0.0 for match in matches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2febbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_count_reward(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if we produce the desired number of think and answer tags associated with `format_reward()`.\n",
    "\n",
    "    Adapted from: https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb#file-grpo_demo-py-L90\n",
    "    \"\"\"\n",
    "\n",
    "    def count_tags(text: str) -> float:\n",
    "        count = 0.0\n",
    "        if text.count(\"<think>\\n\") == 1:\n",
    "            count += 0.25\n",
    "        if text.count(\"\\n</think>\\n\") == 1:\n",
    "            count += 0.25\n",
    "        if text.count(\"\\n<answer>\\n\") == 1:\n",
    "            count += 0.25\n",
    "        if text.count(\"\\n</answer>\") == 1:\n",
    "            count += 0.25\n",
    "        return count\n",
    "\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_tags(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3949fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_funcs(script_args) -> list[Callable]:\n",
    "    REWARD_FUNCS_REGISTRY = {\n",
    "        \"accuracy\": accuracy_reward,\n",
    "        \"format\": format_reward,\n",
    "        # \"reasoning_steps\": reasoning_steps_reward,\n",
    "        # \"cosine\": get_cosine_scaled_reward(\n",
    "        #     min_value_wrong=script_args.cosine_min_value_wrong,\n",
    "        #     max_value_wrong=script_args.cosine_max_value_wrong,\n",
    "        #     min_value_correct=script_args.cosine_min_value_correct,\n",
    "        #     max_value_correct=script_args.cosine_max_value_correct,\n",
    "        #     max_len=script_args.cosine_max_len,\n",
    "        # ),\n",
    "        # \"repetition_penalty\": get_repetition_penalty_reward(\n",
    "        #     ngram_size=script_args.repetition_n_grams,\n",
    "        #     max_penalty=script_args.repetition_max_penalty,\n",
    "        # ),\n",
    "        # \"length\": len_reward,\n",
    "        # \"code\": update_wrapper(\n",
    "        #     partial(\n",
    "        #         code_reward,\n",
    "        #         num_parallel=script_args.parallel_code_exec_per_proc,\n",
    "        #         provider_type=script_args.code_provider,\n",
    "        #         enforce_same_language=getattr(script_args, \"enforce_same_language\", False),\n",
    "        #     ),\n",
    "        #     code_reward,\n",
    "        # ),\n",
    "        # \"binary_code\": update_wrapper(\n",
    "        #     partial(\n",
    "        #         binary_code_reward,\n",
    "        #         num_parallel=script_args.parallel_code_exec_per_proc,\n",
    "        #         provider_type=script_args.code_provider,\n",
    "        #         enforce_same_language=getattr(script_args, \"enforce_same_language\", False),\n",
    "        #     ),\n",
    "        #     binary_code_reward,\n",
    "        # ),\n",
    "        # \"ioi_code\": update_wrapper(\n",
    "        #     partial(\n",
    "        #         ioi_code_reward,\n",
    "        #         test_batch_size=script_args.code_eval_test_batch_size,\n",
    "        #         provider_type=getattr(script_args, \"ioi_provider\", \"piston\"),\n",
    "        #     ),\n",
    "        #     ioi_code_reward,\n",
    "        # ),\n",
    "        # \"cf_code\": update_wrapper(\n",
    "        #     partial(\n",
    "        #         cf_code_reward,\n",
    "        #         test_batch_size=script_args.code_eval_test_batch_size,\n",
    "        #         scoring_mode=script_args.code_eval_scoring_mode,\n",
    "        #     ),\n",
    "        #     cf_code_reward,\n",
    "        # ),\n",
    "        # \"code_format\": get_code_format_reward(language=script_args.code_language),\n",
    "        \"tag_count\": tag_count_reward,\n",
    "        # \"soft_overlong_punishment\": get_soft_overlong_punishment(\n",
    "        #     max_completion_len=script_args.max_completion_len,\n",
    "        #     soft_punish_cache=script_args.soft_punish_cache,\n",
    "        # ),\n",
    "    }\n",
    "    reward_funcs = [REWARD_FUNCS_REGISTRY[func] for func in script_args.reward_funcs]\n",
    "\n",
    "    return reward_funcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4bd91",
   "metadata": {},
   "source": [
    "### è¨“ç·´è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7bcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_args = GRPOScriptArguments(\n",
    "    dataset_name=\"open-r1/OpenR1-Math-220k\",\n",
    "    dataset_prompt_column=\"problem\",\n",
    "    reward_funcs=[\"accuracy\", \"format\", \"tag_count\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(\n",
    "    bf16=True,\n",
    "    use_vllm=True,\n",
    "    do_eval=False,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    gradient_accumulation_steps=16,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    # hub_model_id=\"DeepSeek-R1-Distill-Qwen-1.5B-GRPO\",\n",
    "    hub_model_id=\"DeepSeek-R1-Distill-Qwen-0.6B-GRPO\",\n",
    "    hub_strategy=\"every_save\",\n",
    "    learning_rate=1.0e-6,\n",
    "    log_completions=True,\n",
    "    log_level=\"info\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine_with_min_lr\",\n",
    "    lr_scheduler_kwargs={\"min_lr_rate\": 0.1},\n",
    "    max_prompt_length=512,\n",
    "    max_completion_length=2048,\n",
    "    max_steps=1, #-1,\n",
    "    # num_generations=16,\n",
    "    num_generations=4,\n",
    "    num_train_epochs=1,\n",
    "    # output_dir=\"data/DeepSeek-R1-Distill-Qwen-1.5B-GRPO\",\n",
    "    output_dir=\"data/DeepSeek-R1-Distill-Qwen-0.6B-GRPO\",\n",
    "    overwrite_output_dir=True,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    per_device_eval_batch_size=1,\n",
    "    # per_device_train_batch_size=16,\n",
    "    per_device_train_batch_size=1,\n",
    "    # push_to_hub=True,\n",
    "    push_to_hub=False,\n",
    "    # report_to=[\"wandb\"],\n",
    "    report_to=[],\n",
    "    # reward_funcs=[\"accuracy\", \"format\", \"tag_count\"],\n",
    "    reward_weights=[1.0, 1.0, 1.0],\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    temperature=0.7,\n",
    "    use_liger_kernel=True,\n",
    "    warmup_ratio=0.1,\n",
    "    system_prompt=\"You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>\",\n",
    "    # chat_template=\"\",\n",
    "    vllm_mode=\"colocate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "# model_revision: main\n",
    "# torch_dtype: bfloat16\n",
    "# attn_implementation: flash_attention_2\n",
    "\n",
    "model_args = ModelConfig(\n",
    "    # model_name_or_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    model_name_or_path=\"Qwen/Qwen3-0.6B-Base\",\n",
    "    model_revision=\"main\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a20d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for last checkpoint\n",
    "last_checkpoint = None\n",
    "\n",
    "if os.path.isdir(training_args.output_dir):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "\n",
    "if last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "    logger.info(f\"Checkpoint detected, resuming training at {last_checkpoint=}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afef070",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"wandb\" in training_args.report_to:\n",
    "    init_wandb_training(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905216e",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fec2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = get_dataset(script_args)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8af0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒãƒƒã‚°ç”¨ã«1000ã‚µãƒ³ãƒ—ãƒ«ã«åˆ¶é™\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].select(range(1000))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f78e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format into conversation\n",
    "def make_conversation(example, prompt_column: str = script_args.dataset_prompt_column):\n",
    "    prompt = []\n",
    "\n",
    "    if training_args.system_prompt is not None:\n",
    "        prompt.append({\"role\": \"system\", \"content\": training_args.system_prompt})\n",
    "\n",
    "    if prompt_column not in example:\n",
    "        raise ValueError(f\"Dataset Question Field Error: {prompt_column} is not supported.\")\n",
    "\n",
    "    prompt.append({\"role\": \"user\", \"content\": example[prompt_column]})\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "dataset = dataset.map(make_conversation)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37080b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in dataset:\n",
    "    if \"messages\" in dataset[split].column_names:\n",
    "        dataset[split] = dataset[split].remove_columns(\"messages\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad312e46",
   "metadata": {},
   "source": [
    "### ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22920fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã¿\n",
    "\n",
    "tokenizer = get_tokenizer(model_args, training_args)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c469ad",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFTæ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "\n",
    "model = get_model(model_args, training_args)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fe630",
   "metadata": {},
   "source": [
    "### å ±é…¬é–¢æ•°ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbccdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reward functions from the registry\n",
    "reward_funcs = get_reward_funcs(script_args)\n",
    "reward_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7f0d9",
   "metadata": {},
   "source": [
    "### GRPOTrainerã®ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=reward_funcs,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[script_args.dataset_train_split],\n",
    "    eval_dataset=(dataset[script_args.dataset_test_split] if training_args.eval_strategy != \"no\" else None),\n",
    "    peft_config=get_peft_config(model_args),\n",
    "    callbacks=get_callbacks(training_args, model_args),\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = None\n",
    "\n",
    "if training_args.resume_from_checkpoint is not None:\n",
    "    checkpoint = training_args.resume_from_checkpoint\n",
    "\n",
    "elif last_checkpoint is not None:\n",
    "    checkpoint = last_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052db8e",
   "metadata": {},
   "source": [
    "### è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df515e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train(resume_from_checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f1e35",
   "metadata": {},
   "source": [
    "### ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train_result.metrics\n",
    "metrics[\"train_samples\"] = len(dataset[script_args.dataset_train_split])\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Save model and create model card\n",
    "##################################\n",
    "# Align the model's generation config with the tokenizer's eos token\n",
    "# to avoid unbounded generation in the transformers `pipeline()` function\n",
    "trainer.model.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "trainer.save_model(training_args.output_dir)\n",
    "\n",
    "# Save everything else on main process\n",
    "kwargs = {\n",
    "    \"dataset_name\": script_args.dataset_name,\n",
    "    \"tags\": [\"open-r1\"],\n",
    "}\n",
    "if trainer.accelerator.is_main_process:\n",
    "    trainer.create_model_card(**kwargs)\n",
    "    # Restore k,v cache for fast inference\n",
    "    trainer.model.config.use_cache = True\n",
    "    trainer.model.config.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Evaluate\n",
    "##########\n",
    "if training_args.do_eval:\n",
    "    metrics = trainer.evaluate()\n",
    "    metrics[\"eval_samples\"] = len(dataset[script_args.dataset_test_split])\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff39f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# push to hub\n",
    "#############\n",
    "if training_args.push_to_hub:\n",
    "    logger.info(\"Pushing to hub...\")\n",
    "    trainer.push_to_hub(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
